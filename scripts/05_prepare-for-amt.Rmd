---
editor_options: 
  chunk_output_type: console
---

# Prepare data for SSF

Here we prepare the data for SSFs using the `amt` package.

## Load libraries and prepare files

```{r}
# libs for data
library(data.table)
library(lubridate)
library(glue)
library(dplyr)
library(tidyr)
library(sf)
library(purrr)

# library for SSF
library(amt)

# plot libraries
library(ggplot2)
library(colorspace)
```

```{r}
# read file names
files <- list.files("data/processed/data_preprocessed",
  pattern = "smooth",
  full.names = TRUE
)
```

## Filter for daytime positions

```{r}
# define daily data threshold
daily_data_threshold <- 100
day_start <- 5
day_end <- 20

# read smoothed data and remove if not sufficient data
data <- lapply(files, function(file) {
  df <- fread(file)
  message(
    glue("data has {nrow(df)} rows")
  )
  df[, time := as.POSIXct(UNIX, origin = "1970-01-01", tz = "Asia/Jerusalem")]

  # get hour and date
  df[, date := date(time)]
  df[, hour := hour(time)]

  # remove nighttime roosts --- this has ALREADY BEEN DONE
  # keeping this in for safety
  df <- df[hour > day_start & hour < day_end, ]

  # split by date
  df_list <- split(df, by = "date")
  
  # remove data with fewer than N rows per day
  df_list <- df_list[unlist(lapply(df_list, function(le) {
    nrow(le) >= daily_data_threshold
  }))]
  
  # handle potentially empty data
  if (!is.null(df_list)) {
    df <- rbindlist(df_list)
    message(
      glue("total daytime data has {nrow(df)} rows")
    )
    return(df)
  }
  else {
    return(NULL)
  }
})

# bind list
data <- rbindlist(data)

# remove unnecessary columns
data[, `#` := NULL]
data = data[, !c("speed_in", "speed_out", "speed_smoothed")]
```

## Prepare for SSF

### Split by id and date

```{r}
# make tibble and nest by id and date + other identifiers
setDF(data)

# nest the tibble, 
tracks <- nest(data,
  data = -matches(c("TAG_ID", "date", "sp", "treat"))
)
```

### Make `amt` objects

```{r}
# make amt objects from the nested data
tracks <- mutate(tracks,
  data = map(data, function(df) {
    amt::make_track(
      tbl = df,
      .x = x,
      .y = y,
      .t = time,
      crs = sp::CRS(
        st_crs(2039)$proj4string
      )
    )
  })
)
```

### Resample to 10 seconds

```{r}
# define resample seconds and tolerance
resample_interval_s = 60
resample_tolerance = 5

# min burst
min_n_burst = 5 # min 5 positions in a row

# resample and filter for steps in burst
tracks = mutate(
    tracks,
    data = lapply(data, function(df) {
      
        # resampling the track to 30 seconds with 5 second tolerance
        amt::track_resample(
            df,
            rate = seconds(resample_interval_s),
            tolerance = seconds(resample_tolerance)
        ) %>%
        
        # filtering for bursts with at least 5 pos
        amt::filter_min_n_burst(
            min_n = min_n_burst
        )
    }),
)
```

### Quality filters

Remove data with less than some threshold (currently 50) positions.

```{r}
min_daily_expected = 50

# filter out data with no rows remaining
tracks = filter(
    tracks,
    purrr::map_lgl(data, function(df) {
        nrow(df) > min_daily_expected
    })
)

# now make steps by burst
tracks = mutate(
    tracks,
    data = map(data, amt::steps_by_burst)
)
```

### Get covariate layer

```{r}
# get ndvi
ndvi = raster("data/rasters/raster_hula_ndvi_transformed.tif")

# get landcover
lc = raster("data/rasters/hula_reverse_classified_sentinel_transformed.tif")

# assign name
names(ndvi) = "ndvi"
names(lc) = "landcover"
```

### Prepare alternate steps

```{r}
# define alternate steps
n_alt_steps = 29

# prepare alternate steps and extract covariates
tracks = mutate(
  tracks,
  data = imap(data, function(.x, .y) {
    
    # messages
    message(
      glue("operating row {.y}")
    )
    
    .x %>%
      # get 9 random potential steps
      amt::random_steps(n = n_alt_steps) %>%
      # get NDVI and landcover
      amt::extract_covariates(ndvi) %>%
      amt::extract_covariates(lc) %>%
      # make landcover a factor
      mutate(
        landcover = factor(landcover)
      )
  })
)
```

## Explore covariates in `amt` tracks

Explore the landcover classes in the tracks, as there needs to be more than one class for factor contrasts.

```{r}
# count LC classes in track
tracks = mutate(
  tracks,
  n_lc = map_int(data, function(df) {
    length(unique(df$landcover))
  })
)
```

```{r}
# barplot of number of landcover classes in data
ggplot(tracks %>% 
         filter(treat != "LongPeriod"))+
  geom_bar(
    aes(
      n_lc > 1,
      fill = n_lc > 1
    ),
    show.legend = FALSE
  )+
  scale_fill_manual(
    values = c(
      "TRUE" = "lightblue",
      "FALSE" = "indianred"
    )
  )+
  scale_x_discrete(
    labels = c("1", "> 1"
    )
  )+
  # scale_y_sqrt(
  #   breaks = c(5, 25, 50, 100, 150)
  # )+
  coord_cartesian(
    ylim = c(0, 110),
    expand = F
  )+
  facet_grid(
    sp ~ treat
  )+
  theme_test(base_size = 8)+
  labs(
    x = "# Landcover classes in track",
    y = "# Daily tracks",
    caption = "Landcover classes are counted after preparing for SSF, including\
    adding 9 random steps."
  )

# save image
ggsave(
  filename = "figures/fig_lc_classes_in_ssf_tracks.png",
  height = 4, width = 3
)
```

### Remove tracks without LC contrasts

```{r}
# remove tracks without landcover contrasts
tracks = filter(
  tracks,
  n_lc > 1
) %>% 
  select(-n_lc)

# goes from 434 daily (mostly sparrows) to 405
```

Data still contains long term sparrow tracking and swallow data.

```{r}
save(tracks, file = "data/processed/data_for_ssf.Rds")
```

