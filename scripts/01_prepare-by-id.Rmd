---
editor_options: 
  chunk_output_type: console
---

# Prepare tracking data by individual

## Load libraries

```{r}
# libs for data
library(data.table)
library(readxl)
library(stringi)
library(glue)

library(RSQLite)
```

### Get `atlastools`

```{r install_atlastools_2, eval=TRUE}
if (!require(remotes)) {
  install.packages("remotes", repos = "http://cran.us.r-project.org")
}

# installation using remotes
if (!require(atlastools)) {
  remotes::install_github("pratikunterwegs/atlastools")
}

library(atlastools)
```

## List data

```{r}
# list data files
data_files <- list.files(path = "data/raw", pattern = "sqlite")
names <- stri_replace_all(data_files, replacement = " ", regex = "\\_")

# split by word
names <- stri_extract_all_words(str = names)

# get genus name and treatment
species <- vapply(names, `[[`, FUN.VALUE = "string", 1)
# treatment <- vapply(names, `[[`, FUN.VALUE = "string", 3)

# data files again with full names
data_files <- list.files(path = "data/raw", pattern = "sqlite", full.names = TRUE)
```

## Load data and split by ID

Load and assign species and treatment.

```{r}
invisible(
  Map(data_files, species, f = function(file, sp) {
    # open connection
    con <- dbConnect(
      drv = SQLite(),
      dbname = file
    )

    # list the tables
    table_name <- dbListTables(con)[3] # 3rd table is localisations

    # prepare to query all tables
    query <- sprintf('select * from \"%s\"', table_name)

    # query the database
    df <- dbGetQuery(conn = con, statement = query)

    # disconnect from database
    dbDisconnect(con)

    # make data table
    setDT(df)

    # assign species
    df[, sp := sp]

    # get unique tags
    tags <- unique(df$TAG)

    # remove *Z covariance
    df[, c("VARZ", "COVXZ", "COVYZ") := NULL]

    # split by tag
    df <- split(df, by = "TAG")

    # looping over tag ID, write to file
    invisible(
      Map(df, tags, f = function(dt, tag) {

        # write to file
        fwrite(
          x = dt,
          file = glue::glue(
            "data/processed/data_id/data_{sp}_{tag}.csv"
          )
        )
      })
    )
  })
)
```

## Get basic temporal tracking metrics

### Read files and get metrics

```{r}
# list data
data_files <- list.files("data/processed/data_id/", full.names = TRUE)

# get metrics
data_metrics <- lapply(data_files, function(file) {
  # read file
  df <- fread(file)

  # convert time
  df[, time := as.POSIXct(as.numeric(TIME) / 1000, tz = "UTC", origin = "1970-01-01")]
  # this is consistent with the
  # time column previously present

  df_summary <- df[, list(
    nfixes = .N,
    days_tracking = as.numeric(
      difftime(max(time), min(time),
        units = "days"
      )
    ),
    start_tracking = min(time),
    end_tracking = max(time)
  ),
  by = c("sp", "TAG")
  ]

  # temporal heatmap
  df[, day := as.Date(time)]
  df_tmp_heat <- df[, list(nfixes = .N),
    by = c("sp", "TAG", "day")
  ]
  rm(df)
  # return a list
  list(
    basic = df_summary,
    heatmap = df_tmp_heat
  )
})

# bind and get data
data_basic <- rbindlist(
  lapply(data_metrics, `[[`, "basic")
)

# write to file
fwrite(data_basic, "data/results/data_basic_tracking_metric.csv")
```

### Write daily fixes to file

```{r}
# get data from list
data_daily_heat <- rbindlist(
  lapply(data_metrics, `[[`, "heatmap")
)

# save data
fwrite(data_daily_heat, file = "data/results/data_daily_fixes.csv")
```

## Prepare RRV data for individuals

### Basic read-in

```{r read_rrv_files}
# list files
files <- list.files(path = "data/raw/", pattern = "xlsx", full.names = T)

# remove long term sparrows
# files <- files[-grep("Long", files)]

# read data
data <- lapply(files, read_xlsx, skip = 1)

# there are warnings related to empty columns because excel is terrible
lapply(data, sapply, function(x) sum(is.na(x)))

# colnames
cols_to_keep <- c("Group", "ID", "Tag", "RRV", "Day", "Date", "calculated RRV")

# keep only useful rows and cols
data <- lapply(
  data, function(df) {
    df <- tibble::as_tibble(df)

    df <- tibble::as_tibble(df) |>
      dplyr::select(dplyr::matches(cols_to_keep))
  }
)

# add col to data element 4, which is long term sparrows
data[[4]]$`calculated RRV` <- NA
```

### Handle date and column names

```{r}
# first bind rows
data <- rbindlist(data, use.names = T)

data <- data[!is.na(Tag)]

# edit names to match previous individual data
setnames(data,
  old = c("Group", "Tag", "calculated RRV", "Date"),
  new = c("treat", "trunc_tag", "rrv_calc", "date")
)

# removes cols
data <- data[, !c("ID", "Day")]
```

### Link RRV to species and individual

```{r}
# read previously summarised data
data_tracking_summary <- fread("data/results/data_basic_tracking_metric.csv")

# select useful columns
# data_tracking_summary <- data_tracking_summary[, c("sp", "treat", "TAG")]

# get last four digits of the tag id
data_tracking_summary[, "tag_4_digit" := stri_sub(TAG, -4, -1)]

# pad the RRV data tag id, ie, make xx01 to 0001
data[, trunc_tag := stri_pad_left(trunc_tag, width = 4, pad = 0)]

data_treat <- unique(data, by = c("trunc_tag", "treat"))

# attach treatment data to tracking metrics
data_tracking_summary_w_rrv <-
  merge(
    data_tracking_summary, data_treat,
    all = F,
    by.y = c("trunc_tag"),
    by.x = c("tag_4_digit")
  )

data_tracking_summary_w_rrv <- data_tracking_summary_w_rrv[
  , !c("tag_4_digit", "date", "rrv_calc")
]

fwrite(data_tracking_summary_w_rrv,
  file = "data/results/data_tracking_metrics_rrv.csv"
)

# join the datasets
data <- merge(data, data_tracking_summary,
  by.x = c("trunc_tag"),
  by.y = c("tag_4_digit"),
  all.x = T, all.y = F
)

# remove old tag and write to file
data <- data[, !"trunc_tag"]

fwrite(data, file = "data/results/data_daily_rrv.csv")
```

```{r}
# summarise some tracking metrics
data_tracking_summary_w_rrv[, .(all_fixes = sum(nfixes))]

# average days tracking
data_tracking_summary_w_rrv[, unlist(
  lapply(.SD, function(x) {
  list(
    mean = mean(x),
    sd = sd(x)
  )
}),recursive = F), .SDcols = "days_tracking", by = c("sp")]

# average postions per day
data_tracking_summary_w_rrv[, list(
  mean(nfixes / days_tracking)
),by="sp"]
#[,list(mean(V1))]

# average positions per minute
data_tracking_summary_w_rrv[, list(avg_fixes = nfixes /
  (days_tracking * 24 * 60)),
by = c("TAG", "sp")
][, list(
  avg_avg_fixes = mean(avg_fixes),
  sd_avg_fixes = sd(avg_fixes)
), by = "sp"]
```

### Summarise wing gap index

```{r}
# read in wing gap index scores
wgi <- fread("data/results/data_daily_rrv.csv")

# summarise by species and molt status
wgi_summary <- wgi[, list(
  wgi_mean = mean(RRV, na.rm = TRUE),
  wgi_sd = sd(RRV, na.rm = TRUE)
), by = c("treat", "sp")]

# save data
fwrite(
  wgi_summary,
  file = "data/results/data_wgi_summary.csv"
)
```

```{r}
# count individuals by species
unique(wgi, by = "TAG")[, .N, by = "sp"]
```

```{r}
# summarise tracking before pre-processing
unique(wgi, by = "TAG")[, .(
  mt = mean(days_tracking), sdt = sd(days_tracking)
),
by = "sp"
]
```
