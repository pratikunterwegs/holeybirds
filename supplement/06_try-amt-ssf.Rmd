---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Try SSF

## Load libraries and prepare files

```{r}
# libs for data
library(data.table)
library(lubridate)
library(tidyverse)
library(raster)

# check for velox and install
library(devtools)
if (!"velox" %in% installed.packages()) {
  install_github("hunzikp/velox")
} else {
  library(velox)
}
library(sf)

# library for atlas data
library(amt)

# plotting
library(ggplot2)
library(ggspatial)
library(colorspace)
```

## Load data

```{r}
files = list.files("data/processed/data_preprocessed", pattern = "smooth",
                   full.names = T)
rrv = read_csv("data/results/data_daily_rrv.csv")
```


```{r}
# read files
data = fread(files[1])
setDF(data)

# make tibble
data = as_tibble(data)

# handle timesteps
data = mutate(
  data, 
  time = as.POSIXct(
    UNIX, origin = "1970-01-01", tz = "Asia/Jerusalem"
  ),
  date = date(time)
) %>% 
  filter(
    d == "D"
  )

# make amt
data = amt::make_track(
  tbl = data, .x = x, .y = y, .t = time,
  # set CRS
  crs = sp::CRS(
    st_crs(2039)$proj4string
  )
)

# resample to 30 s with a 5 second tolerance
data_resamp = amt::track_resample(
  data,
  rate = seconds(30),
  tolerance = seconds(3)
) %>% 
  
  # filter bursts with at least 5 points
  # this is the filtering out of proto-patches essentially
  amt::filter_min_n_burst(
    min_n = 5
  ) %>% 
  amt::steps_by_burst()
```

## Get covariate layer

```{r}
# get ndvi
ndvi = raster("data/rasters/raster_hula_ndvi_transformed_crop.tif")
# get landcover
lc = raster("data/rasters/raster_hula_lc10_transformed_crop.tif")

# assign name
names(ndvi) = "ndvi"
names(lc) = "landcover"
```

## Prepare for amt

```{r}
# make random steps
data_resamp = data_resamp %>% 
  amt::random_steps(n = 19)
```

```{r}
# radius in metres
use_radius = 10
```

## Extract destination mean NDVI and proportion LC

### Make buffers

```{r}
step_end_buffer = select(data_resamp, x2_, y2_, case_, step_id_) %>% 
  st_as_sf(coords = c("x2_", "y2_"), crs = 2039) %>% 
  st_buffer(dist = use_radius)
```

### Extract from buffers

```{r}
# ndvi operation
ndvi_velox = velox(ndvi)
mean_ndvi = ndvi_velox$extract(
  sp = step_end_buffer, df = TRUE,
  fun = function(x) mean(x, na.rm = T)
)
mean_ndvi = rename(mean_ndvi, ndvi = out)

# landcover operation
lc_velox = velox(lc)
lc_vals = lc_velox$extract(sp = step_end_buffer, df = TRUE)
lc_prop =
  lc_vals %>% 
  rename(lc = "do.call..rbind...out.") %>% 
  count(ID_sp, lc) %>% 
  group_by(ID_sp) %>% 
  mutate(
    lc = sprintf("lc_%i", lc),
    prop = n / sum(n)
  ) %>% 
    select(-n) %>% 
    pivot_wider(
      names_from = lc,
      values_from = prop,
      values_fill = list(prop = 0)
    ) %>% 
  ungroup()
```

### Join with buffers

```{r}
# create key
step_end_buffer$ID_sp = seq(nrow(step_end_buffer))
# join
step_end_buffer = inner_join(
  step_end_buffer, mean_ndvi
) %>% 
  inner_join(
    lc_prop
  )
```

### Join with data

```{r}
data_resamp = mutate(data_resamp,
                     ID_sp = seq(nrow(data_resamp))) %>% 
  inner_join(mean_ndvi) %>% 
  inner_join(lc_prop) %>% 
  select(-ID_sp)
```

## Extract step characteristics

We want to know how much of the step (x1,y1) to (x2,y2) is over open areas, LC 0 and LC 2.

### Make step spatial lines

Make lines and sample points along them.

```{r}
# get end points
steps = select(data_resamp, x1_, y1_, x2_, y2_)

# make sf lines
steps$geometry = pmap(steps, function(x1_, y1_, x2_, y2_) {
  # make linear path
  step_path = st_linestring(
    matrix(c(x1_, y1_, x2_, y2_), nrow = 2, byrow = T)
  )
  
  step_path
})

# MAKE SFC
steps$geometry = st_sfc(steps$geometry, crs = 2039)

# get length
steps$path_length = st_length(steps$geometry)

# sample it every 10m
steps$path_samples = st_line_sample(steps$geometry, density = 1 / 10)

# path ends appear to be ignored
# many paths are very short
steps$path_samples = st_buffer(steps$path_samples, 5)

# make sf
steps = st_sf(steps, sf_column_name = "path_samples")
```

### Extract mean NDVI along path

```{r}
# THIS CAN NOW BE PASSED TO VELOX -- some should give NAs due to EMPTY
ndvi_path = ndvi_velox$extract(sp = steps, fun = mean)
```

### Extract proportion open along path

```{r}
# NEEDS TO BE ADDED
```

The question is, how to handle NA or similar values which are due to very short paths.
Take the mean of start and end, should be essentially the same.

## Fitting SSF

Modify formula -- one for all, or model selection? Go per Thjurfell et al. 2014 Move Ecol.

```{r}
m1 = data_resamp %>% 
  amt::fit_issf(
    case_ ~ ndvi + lc_0 + lc_1 + lc_2 + lc_3 + lc_4 + lc_5 + strata(step_id_)
  )

# get distribution of step lengths
step_dist = sl_distr(m1)

# adjust distribution shape based on model
shape_day = step_dist$params$shape + coef(m1)["sl_"]
shape_night = step_dist$params$shape + coef(m1)["sl_"] + coef(m1)["sl_:tod_end_night"]

step_dist$params$scale * c(shape_day, shape_night)
```

### Utilisation distribution

```{r}
# set values NA to 0
raster::values(lc)[is.na(raster::values(lc))] = 0
```

Does not work on LC data as it is too coarse.
Trying on finer LC data but interpretations are different.

### SSUD

```{r}
mk = amt::movement_kernel(
  scale = step_dist$params$scale,
  shape = step_dist$params$shape + m1$model$coefficients["sl_"],
  template = lc
)

hk = amt::habitat_kernel(
  coef = list(ndvi = coef(m1)["ndvi"]), resources = ndvi, exp = TRUE
)

ssud = amt::simulate_ud(
  movement_kernel = mk,
  habitat_kernel = hk,
  start = as.numeric(
    data_resamp[1, c("x1_", "y1_")]
  ),
  n = 1e7
)

# remove zero values
values(ssud)[values(ssud) < 1e-5] = NA

writeRaster(
  ssud,
  filename = "data/testssud.tif",
  overwrite = T
)
```

### TUD

```{r}
# made tud
tud = amt::simulate_tud(
  mk, hk, as.numeric(data_resamp[floor(nrow(data_resamp)/2), c("x1_", "y1_")]),
  n = 72, n_rep = 1e2
)

writeRaster(
  tud,
  filename = "data/testtud.tif",
  overwrite = T
)
```

